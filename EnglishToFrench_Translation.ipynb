{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSufS1bNUmm9"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install rouge-score nltk\n",
        "#loading PyTorch\n",
        "!pip install torch\n",
        "!pip install sentencepiece\n",
        "!pip install sacrebleu\n",
        "!pip install evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "xFa8QoHZbJ_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Dataset from HuggingFace\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"kde4\", lang1=\"en\", lang2=\"fr\")"
      ],
      "metadata": {
        "id": "76hbrDm_bLjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "ryUMaeH_bas2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to create our own validation set\n",
        "split_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=20)\n",
        "split_datasets"
      ],
      "metadata": {
        "id": "Vt5krEAzbkGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rename the \"test\" key to \"validation\"\n",
        "split_datasets[\"validation\"] = split_datasets.pop(\"test\")"
      ],
      "metadata": {
        "id": "g4F4esnMbod8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_datasets[\"train\"][1][\"translation\"]"
      ],
      "metadata": {
        "id": "LafzSt8_bzpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "2csaxCA6VOle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs, text_target=targets, max_length=max_length, truncation=True\n",
        "    )\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "9g_uhwxGVcsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = split_datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=split_datasets[\"train\"].column_names,\n",
        ")"
      ],
      "metadata": {
        "id": "-0p2XgrgVfTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "fGkZFdtmVijY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "p93g-GSQVtUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample\n",
        "predictions = [\n",
        "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
        "]\n",
        "references = [\n",
        "    [\n",
        "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
        "    ]\n",
        "]\n",
        "metric.compute(predictions=predictions, references=references)"
      ],
      "metadata": {
        "id": "1NedL4DrV93I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # In case the model returns more than the prediction logits\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100s in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": result[\"score\"]}"
      ],
      "metadata": {
        "id": "K-nf12pGWJ9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"marian-finetuned-kde4-en-to-fr\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "yllTDnxLWK-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "rlzBqcuSWPNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(max_length=max_length)"
      ],
      "metadata": {
        "id": "7ynh9zpHWVav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Bd2BAvOIWdon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}